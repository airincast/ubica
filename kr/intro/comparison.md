# 다른 지표와의 차이
이 문서에서는 UBICA와 다른 지표 간의 차이를 비교합니다.

## 지표간 비교
* **UBICA** vs. **튜링 테스트**\
가장 유명한 평가 방법인 튜링 테스트는 대화 능력이라는 단순한 기준을 통해 AI와 인간 사이를 구분하는 데에 중점을 둡니다. 반면 **UBICA**는 일관성, 창의성, 감정 표현 등 보다 다양한 기준으로 AI와 인간 사이의 유사성을 확인하는 데에 중점을 둡니다.
* **UBICA** vs. **러브레이스 테스트**\
AI의 창의성을 평가하기 위한 러브레이스 테스트는 AI가 얼만큼 예측 불가능하고 독창적인 결과물을 생성할 수 있는지를 판단합니다. **UBICA**는 여기서 한 단계 나아가, 생성된 결과물이 상황에 얼마나 어울리는지 등을 종합적으로 평가합니다.
* **UBICA** vs. **EVA 프레임워크**\
AI의 개인화 반응을 평가할 목적으로 설계된 EVA 프레임워크는 주로 감정 표현, 상호작용 능력 등을 평가합니다. 여기에 **UBICA**는 성격 일관성, 창의성, 몰입감, 자연스러움 등, EVA에서는 잘 다루지 않는 다른 지표들을 포함합니다.
* **UBICA** vs. **PARADISE 프레임워크**\
대화의 효율성과 목표 달성도를 측정하기 위해 설계된 PARADISE 프레임워크는 대화 시스템의 성능과 사용자 만족도를 주로 평가합니다. 그러나 **UBICA**는 감정 표현, 표현의 창의성 등을 추가적으로 평가해, 대화의 몰입감까지 측정할 수 있습니다.
* **UBICA** vs. **UX 연구**\
사용자 경험 연구는 상호작용 과정에서 사용자들이 느끼는 만족감, 신뢰도, 호감도 등을 조사하는 평가입니다. 여기까지는 **UBICA**와 유사하지만, **UBICA**는 성격 일관성, 창의성 등을 추가적으로 평가 항목에 넣고 있습니다.
* **UBICA** vs. **자언어 처리 성능 평가**\
자연어 처리 성능 평가는 AI의 언어 이해와 생성 능력을 공학적인 접근으로 평가하고 있습니다. 그러나 **UBICA**는 생성된 언어 표현이 얼마나 창의적인지, 또 그 감정 표현은 적절했는지 등을 두루 평가하도록 설계되었습니다.
* **UBICA** vs. **SIB**\
AI의 사회적 지능을 평가하기 위해 설계된 SIB는 감정 인식, 공감 능력, 사회적 상식 등을 측정합니다. **UBICA**는 여기에 창의성과 매력 등을 추가해, 인간다운 상호작용을 넘어 인간 이상의 상호작용을 할 수 있는지도 평가합니다.

## 각 지표 설명
**튜링 테스트 (Turing Test)**\
가장 유명한 AI 평가 방법 중 하나로, AI가 인간과 구별되지 않는 수준의 대화 능력을 갖추었는지 판단합니다. 그러나 이 테스트는 AI의 인간다움을 평가하는 데 초점을 맞추기보다는, 단순히 인간과의 구분 여부에 중점을 둡니다. 따라서 캐릭터의 일관성이나 창의성, 감정 표현 등 UBICA에서 강조하는 요소들을 충분히 반영하지 못합니다.

**러브레이스 테스트 (Lovelace Test)**\
AI의 창의성을 평가하기 위한 테스트로, AI가 예측 불가능하고 독창적인 결과물을 생성할 수 있는지를 판단합니다. 그러나 이 역시 캐릭터의 일관성이나 상호작용의 자연스러움 등을 종합적으로 평가하지는 않습니다.

**EVA (Evaluation of Virtual Agents) 프레임워크**\
가상 에이전트나 캐릭터 AI를 평가하기 위한 방법으로, 감정 표현, 사회적 상호작용 능력, 개인화된 반응 등을 평가합니다. UBICA와 마찬가지로 캐릭터의 인간다운 상호작용에 초점을 맞추지만, 평가 기준이나 세부 항목에서 차이가 있을 수 있습니다.

**PARADISE 프레임워크**\
대화 시스템의 성능과 사용자 만족도를 평가하기 위한 방법으로, 대화의 효율성과 목표 달성도 등을 측정합니다. 하지만 캐릭터의 감정 표현이나 창의성보다는 기능적 측면에 집중합니다.

**사용자 경험 (UX) 연구**\
인공지능과의 상호작용에서 사용자들이 느끼는 만족감, 신뢰도, 호감도 등을 조사하여 AI를 평가합니다. 이는 UBICA의 몰입감이나 만족감과 유사한 측면을 다루지만, 캐릭터의 성격 일관성이나 창의성 등에 대한 구체적인 평가 기준은 부족할 수 있습니다.

**자연어 처리 성능 평가 (예: GLUE Benchmark)**\
AI 모델의 언어 이해와 생성 능력을 평가하기 위한 벤치마크로, 문맥 이해, 추론 능력 등을 측정합니다. 그러나 이는 캐릭터 AI의 개성이나 감정 표현과는 거리가 있습니다.

**Social Intelligence Benchmark (SIB)**\
AI의 사회적 지능을 평가하기 위한 방법으로, 감정 인식, 공감 능력, 사회적 상식 등을 측정합니다. 캐릭터 AI의 인간다운 상호작용을 평가하는 데 유용하지만, UBICA처럼 캐릭터의 매력이나 창의적인 반응을 구체적으로 평가하지는 않습니다.