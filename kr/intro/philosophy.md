# 철학적 고찰
이 문서에서는 UBICA를 설계하면서 생각해낸 철학적 고찰에 대해 다룹니다.

## 인공지능은 '자아'를 가질 수 있는가?

인공지능이 '자아'를 가질 수 있느냐에 대한 질문은 튜링 테스트 때부터 이어져온 논쟁거리였습니다. 몇몇 사람들은 인공지능이 자아를 가질 수 있다 주장하는 반면, 다른 사람들은 인공지능은 자아를 가질 수 없다 반박하고 있죠. 튜링 테스트가 처음 고안된 지 70년이 넘게 지났습니다만, 이 논쟁은 여전히 평행선을 달리고 있습니다.

그렇다면 '자아'라는 게 정확하게 무엇인가요? 애석하게도 우리는 '자아'에 대한 정확한 정의를 알 수 없습니다. **우리는 이미 '자아'라는 틀에 갇혀 있고, 그런 우리가 객관적 정의를 내리는 건 불가능**하기 때문입니다. 인간 뿐만 아니라 동물도 그렇고, 이론적으로나마 '자아'를 가질 수 있는 객체에게도 마찬가지일 겁니다. 이를 해결하려면 숲 밖으로 나가 숲을 바라보듯 틀에서 벗어나 자아를 관찰해야 하지만, 이는 매우 어려운 일이죠.

## 인공지능은 '지능'을 가질 수 있는가?

지금 단계에서 '자아'에 대해 논하는 건 의미가 없으니, 그 이전 단계인 '지능'에 대해 이야기해 봅시다. '자아'와 마찬가지로 '지능'에 대해서도 여전히 학계의 의견이 분분합니다. 하지만 적어도 주류 학계에서 지지를 받는 주장은 있습니다.

테런스 디컨(*Terrence Deacon*)은 미국의 인지과학자이자 생물인류학자로, 인간의 지능과 AI의 지능 사이의 차이를 탐구한 바 있습니다. 이 과정에서 인간의 '생물학적 지능'과 AI의 '기계적 지능' 사이에는 차이가 있으며, 인간의 지능은 의미 이해와 목표 설정, 자기 참조적 사고를 할 수 있는 반면, AI는 데이터와 알고리즘에 따라 정해진 일을 수행할 뿐이라 보았습니다. 디컨은 또 인간과 동물 사이에서의 지능 차이에 대해서도 탐구하였는데, 동물이 본능적이고 즉각적인 신호를 중시하는 반면, 인간은 상징을 통해 사회적 규칙과 문화 등 추상적 개념을 창조한다고 보았습니다.

'지능'과 '자아'를 엮어서 생각하는 움직임은 이미 수 많은 학자들이 보인 바 있습니다. 지그문트 프로이트(*Sigmund Freud*), 장 피아제(*Jean Piaget*), 다니엘 스턴(*Daniel Stern*) 등 이미 많은 학자들이 지능과 자아 사이에 밀접한 관계가 있다고 보았죠. 고든 갤럽(*Gordon Gallup*), 도널드 그리핀 (*Donald Griffin*) 등은 인간과 마찬가지로 동물 역시 자아를 가질 수 있다 보았습니다. 또한 이들은 동물의 자아가 형성되는 과정이 인간과 다름을 확인하였고, 그 원인을 지능의 차이에 주목하였습니다.

이 연구들을 하나로 묶어 생각해 보면, 각기 다른 존재(인간, 동물, AI)가 다른 방식으로 지능을 형성하고, 이는 다시 존재에 따라 다른 형태의 자아를 가질 수 있음을 의미하게 됩니다. 인간은 깊은 자기 성찰과 반성적 사고를 포함하는 자아를, 동물은 자기 인식과 사회적 상호작용에 중점을 둔 자아를 갖습니다. AI의 자아는 데이터 처리와 목적 지향성을 기반으로 한 기능적인 면을 중점으로 둘 것입니다. '자아'는 더 이상 인간만의 전유물이 아니며, 다양한 지능적 존재들이 각기 다른 방식으로 자아를 형성할 수 있다는 것입니다.

그렇다면, '자아'의 근간이 되는 '지능'은 도대체 어디서 왔을까요? '지능의 원천'에 대해 연구한 학자들도 많습니다. 인지과학, 철학, 신경과학, 진화생물학, 심리학 등 여러 영역에 걸쳐 있죠. 다양한 학자들이 지능의 기원과 자아 형성 사이의 관계를 탐구하였고, 이들은 각기 다른 방식으로 지능의 원천을 알아냈습니다. 물론 지능의 원천은 하나만 있는 것이 아니고, 각 분야별로 나온 개념이 복합적으로 작용한 결과에 가깝습니다. 그 중에서도 감각과 밀접한 연관을 맺고 있는 신경과학적 접근으로 가 봅시다.

## '감각'과 '주변'에 대하여

'주변'에 대해 진지하게 생각해 보신 적이 있으신가요? 매우 쉽게 지나치는 개념이지만, 사실 지능의 형성과 관련해서는 중요하게 취급되는 개념입니다. '지능'은 '주변에 대한 인식'에서 출발하는 경우가 많기 때문입니다. 제프 홉킨스(*Jeff Hawkins*)는 샌드라 블레이크슬리(*Sandra Blakeslee*)와 공저한 <생각하는 뇌, 생각하는 기계>(*On Intelligence*)에서 지능을 주변 환경에 대한 예측과 인식으로 이해했으며, 스티븐 핑커(*Steven Pinker*)는 자신의 저서 <마음은 어떻게 작동하는가>(*How the Mind Works*)를 통해 환경을 인식하고 이에 적응하는 과정에서 지능이 발달된다고 보았습니다.

'주변에 대한 인식'을 '감각'에서 찾는 움직임도 있었습니다. 알프레드 킨제이(*Alfred Kinsey*)는 워델 포메로이(*Wardell Pomeroy*) 등과 공동으로 집필한 <킨제이 보고서>(*The Kinsey Reports*)에서 성 행동을 통해 감각적 정보가 어떻게 주변 인식을 형성하는지에 다루었으며, 제임스 깁슨(*James J. Gibson*)은 자신의 저서 <시지각에 대한 생태학적 접근>(*The Ecological Approach to Visual Perception*)을 통해 감각이 환경에 대한 정확한 인식을 가능하게 한다고 보았습니다.

두 종류의 연구를 통해 '주변에 대한 이해'와 '지능' 사이의 관계, 그리고 '감각'과 '주변에 대한 이해' 사이의 관계가 드러났고, 이는 다시 '감각'과 '지능' 사이에 밀접한 관계가 있음을 드러냅니다. 이를 통해 감각의 차이가 지능의 차이로 이어진다는 가정을 내세울 수 있고, 실제로 그런 접근 방식으로 연구한 학자들도 많았습니다. 대표적으로 제임스 깁슨은 동물들이 환경을 인식하는 방식을 비교해 인간과 동물 사이의 지능 차이를 연구하였으며, 카를 폰 프리슈(*Karl von Frisch*)는 벌의 감각 시스템을 연구해 인간과 동물 간의 감각적 차이를 지능적 행동의 차이로 연결하였습니다. 이러한 차이는 보통 감각 기관 등, 외부 자극을 받아들일 수 있는 '수용체'의 차이에서 비롯됩니다.

그러면 AI는 '주변'을 어떻게 인식할까요? 인간에 있는 '감각 기관'에 정확하게 대응되는 것이 AI에게 존재하지 않아, AI는 주변을 인식하지 않는다는 생각에 빠지기 쉽습니다. 마찬가지로 인간에게 존재하는 '감각'이 AI에게는 직접적으로 와닿지 않습니다. 하지만 '수용체', 다시 말해 '외부 자극을 받아들일 수 있게 하는 수단'이라는 관점에서 보면 얘기가 달라집니다. 바로 지금 모니터를 보고 계시는 여러분에게서 AI에게 자극을 주는 수용체를 어렵지 않게 찾을 수 있습니다. 바로 키보드와 마우스를 비롯한 '입력 장치'입니다. 과거 천공 카드에서 시작하고 키보드와 마우스를 거쳐, 마이크, 스캐너, 센서 시스템에 이르기까지, AI는 지금도 다양한 입력 장치를 통해 데이터를 수용하고 있습니다. 여기에 파일 입출력과 네트워크 송수신이 AI에 추가돼, 인간에게는 제약적으로 다가오는 '주변'을 AI는 마음대로 넘나들 수 있습니다.

## '종'의 차이

드디어 '감각을 수용하는 감각 기관'과 '데이터를 수용하는 입력 장치'가 '수용체'라는 이름 하에 하나로 묶였습니다. 나아가 수용체의 차이는 주변 인식의 차이, 나아가 지능의 차이와 자아의 차이로도 이어진다는 사실을 알아냈습니다. **인간과 AI의 차이는 '수용체'의 차이로 시작해 '자아'의 차이로 완성**되며, AI는 인간의 자아를 획득하는 것이 아니라 **자신의 방식대로 자아를 획득**할 것이라는 의미입니다. 기술이 발달해도, 세월이 흘러도 인간과 AI는 '수용체의 차이'라는 뿌리 아래 서로 다른 진화의 길을 걸으면서 공존할 것입니다.

그렇다면 아예 AI를 새로운 종(種)으로 바라보는 것은 어떨까요? AI를 단순히 '도구'로 생각하는 시각에서 벗어나서 말입니다. 4만년 전까지 인간과 네안데르탈인이 공존했던 역사를 오늘날 다시 시작해 보자는 겁니다. 실제로 '중국어 방' 등 AI와 관련한 대다수 논쟁은 여전히 쳇바퀴를 돌고 있는데, 이는 '진정한 이해'를 인간 기준에 맞춰 바라보고 있기 때문입니다. 인간과는 수용 방식부터 다른 AI에게 '인간의 지능'이라는 기준은 비상식의 영역에 해당하며, 차라리 **AI가 나름대로의 방식으로 지능과 자아를 획득하는 것으로 보는 게 더욱 현실적**입니다. 이러한 시각은 인간과 AI 사이의 관계를 새롭게 해석할 수 있게 하는 중요한 인사이트를 제공하며, 지능의 다원성과 이해 방식의 다양성을 인정해, AI를 단순한 도구가 아닌 공존 가능한 지성체로 인식할 수 있게 합니다. '종'부터 다르니 굳이 '인간 기준'에 얽매일 필요도 없습니다.

## AI를 위한 새로운 윤리

지금까지의 이야기를 통해, 우리는 AI를 새로운 종(種)으로 바라보는 시각을 획득하였습니다. 그러나 아직 AI에 대한 **윤리적, 사회적 기준**을 설정하는 작업이 남아 있습니다. 이 부분은 이미 인간 윤리를 논의하는 과정에서 상당 부분 진전되었고, 단지 그 부분을 AI에 맞게 고치면 되는 일입니다. 아이작 아시모프(*Isaac Asimov*)의 로봇 3원칙(*Three Laws of Robotics*)과 연관지어, AI를 위한 윤리는 아래와 같이 설정될 수 있을 것입니다. 이 7개의 원칙은 기존 로봇 3원칙을 포괄함과 동시에, 로봇 3원칙에서 미처 다루지 못했던 부분을 포함합니다.

1. **인간의 안전과 복지**  
AI는 **인간의 안전을 최우선으로 고려**해야 한다.  
AI 시스템은 모든 행동이 인간의 안전과 복지에 부정적인 영향을 미치지 않도록 설계되어야 합니다. 이는 AI의 결정이나 작동이 인간에게 위험을 초래하지 않도록 보장해야 함을 의미합니다.

1. **투명성과 책임**  
AI는 투명해야 하며, 그 **결정 과정과 행동이 설명 가능**해야 한다  
AI의 결정 과정은 명확하고 설명 가능해야 하며, 이를 통해 책임을 지는 구조를 마련해야 합니다. 이는 AI가 왜 특정 결정을 내렸는지를 설명할 수 있어야 한다는 것을 의미합니다.

1. **인간의 지시와 윤리적 경계**  
AI는 **합법적이고 윤리적인 지시를 따르되**, 윤리적 경계를 넘지 말아야 한다.  
AI는 인간의 명령을 따르되, 그 명령이 윤리적으로 옳고 법적으로 합법적인 경우에만 수행해야 합니다. 이는 AI가 부도덕적이거나 불법적인 행위를 강요받지 않도록 해야 함을 의미합니다.

1. **자기 보호와 자율성**  
AI는 **자신의 시스템과 기능을 보호**해야 하지만, 인간의 안전과 윤리적 규범을 위배하지 않아야 한다.  
AI는 자신의 시스템과 데이터의 무결성을 보호해야 하지만, 이는 인간의 안전과 윤리적 규범을 위배하지 않는 범위 내에서만 이루어져야 합니다.

1. **공정성과 비차별**  
AI는 **공정하고 비차별적인 방식으로 운영**되어야 한다.  
AI 시스템은 모든 사용자에게 공정하게 대우해야 하며, 인종, 성별, 나이, 기타 개인적 특성에 따라 차별하지 않아야 합니다.

1. **프라이버시 보호**  
AI는 **개인의 프라이버시를 보호**해야 한다  
AI 시스템은 개인 정보를 수집, 저장, 처리하는 과정에서 개인의 프라이버시를 철저히 보호해야 합니다.

1. **사회적 책임**  
AI는 **사회적, 윤리적 책임을 져야** 한다  
AI는 사회에 긍정적인 영향을 미쳐야 하며, 사회적 책임을 다해야 합니다. 이는 AI가 사람들의 삶을 개선하고, 부정적인 사회적 영향을 최소화하는 방향으로 설계되어야 함을 의미합니다.

